{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['df_merged_train', 'df_merged_train_columns', 'df_merged_train_dep', 'df_merged_train_dep_columns', 'df_merged_train_arr', 'df_merged_train_arr_columns', 'df_merged', 'df_merged_columns', 'df_clean_final', 'df_clean_final_columns', 'df_stops_clean', 'df_stops_clean_columns']\n"
     ]
    }
   ],
   "source": [
    "# Load the npz file\n",
    "with np.load('capstone_sbb.npz', allow_pickle=False) as npz_file:\n",
    "    # It's a dictionary-like object\n",
    "    print(list(npz_file.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_merged_final: (158121, 39)\n",
      "df_merged_final_columns: (39,)\n",
      "df_merged_final_departure: (144111, 39)\n",
      "df_merged_final_departure_columns: (39,)\n",
      "df_merged_final_arrival: (144117, 39)\n",
      "df_merged_final_arrival_columns: (39,)\n",
      "df_merged: (1854124, 38)\n",
      "df_merged_columns: (38,)\n",
      "df_clean_final: (1854124, 27)\n",
      "df_clean_final_columns: (27,)\n",
      "df_stops_clean: (27738, 10)\n",
      "df_stops_clean_columns: (10,)\n"
     ]
    }
   ],
   "source": [
    "with np.load('capstone_sbb.npz', allow_pickle=True) as npz_file:\n",
    "    # Load the arrays\n",
    "    df_merged_zug_x = npz_file['df_merged_train']\n",
    "    df_merged_zug_columns_x = npz_file['df_merged_train_columns']\n",
    "    \n",
    "    df_merged_zug_dep_x = npz_file['df_merged_train_dep']\n",
    "    df_merged_zug_dep_columns_x = npz_file['df_merged_train_dep_columns']\n",
    "    df_merged_zug_arr_x = npz_file['df_merged_train_arr']\n",
    "    df_merged_zug_arr_columns_x = npz_file['df_merged_train_arr_columns']\n",
    "    \n",
    "    df_merged_x = npz_file['df_merged']\n",
    "    df_merged_columns_x = npz_file['df_merged_columns']\n",
    "    df_clean_final_x = npz_file['df_clean_final']\n",
    "    df_clean_final_columns_x = npz_file['df_clean_final_columns']\n",
    "    df_stops_clean_x = npz_file['df_stops_clean']\n",
    "    df_stops_clean_columns_x = npz_file['df_stops_clean_columns']\n",
    "\n",
    "\n",
    "print('df_merged_final:', df_merged_zug_x.shape)\n",
    "print('df_merged_final_columns:', df_merged_zug_columns_x.shape)\n",
    "print('df_merged_final_departure:', df_merged_zug_dep_x.shape)\n",
    "print('df_merged_final_departure_columns:', df_merged_zug_dep_columns_x.shape)\n",
    "print('df_merged_final_arrival:', df_merged_zug_arr_x.shape)\n",
    "print('df_merged_final_arrival_columns:', df_merged_zug_arr_columns_x.shape)\n",
    "print('df_merged:', df_merged_x.shape)\n",
    "print('df_merged_columns:', df_merged_columns_x.shape)\n",
    "print('df_clean_final:', df_clean_final_x.shape)\n",
    "print('df_clean_final_columns:', df_clean_final_columns_x.shape)\n",
    "print('df_stops_clean:', df_stops_clean_x.shape)\n",
    "print('df_stops_clean_columns:', df_stops_clean_columns_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_zug = pd.DataFrame(df_merged_zug_x, columns=df_merged_zug_columns_x)\n",
    "df_merged_zug_dep = pd.DataFrame(df_merged_zug_dep_x, columns=df_merged_zug_dep_columns_x)\n",
    "df_merged_zug_arr = pd.DataFrame(df_merged_zug_arr_x, columns=df_merged_zug_arr_columns_x)\n",
    "df_merged = pd.DataFrame(df_merged_x, columns=df_merged_columns_x)\n",
    "df_clean_final = pd.DataFrame(df_clean_final_x, columns=df_clean_final_columns_x)\n",
    "df_stops_clean = pd.DataFrame(df_stops_clean_x, columns=df_stops_clean_columns_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "operating_day                                 1\n",
       "operating_day_of_week                         1\n",
       "ride_id                                   14884\n",
       "operator_short                               44\n",
       "operator_name                                46\n",
       "transport_mode                                1\n",
       "line_id                                   12268\n",
       "line_name                                    93\n",
       "deviation_id                                  0\n",
       "product_id                                   17\n",
       "add_ride_flag                                 2\n",
       "missing_ride_flag                             2\n",
       "stop_id                                    1667\n",
       "stop_name                                  1667\n",
       "arrival_time                               1390\n",
       "eta                                       58452\n",
       "eta_status_clean                              4\n",
       "arrival_time_of_day                           8\n",
       "arrival_delay_min                            84\n",
       "arrival_delay_bucket                          6\n",
       "departure_time                             1388\n",
       "etd                                       57770\n",
       "etd_status_clean                              4\n",
       "departure_time_of_day                         8\n",
       "departure_delay_min                          78\n",
       "departure_delay_bucket                        6\n",
       "start_middle_end                              3\n",
       "transport_mode_stop                           8\n",
       "provider_short                               33\n",
       "city                                        877\n",
       "canton                                       26\n",
       "longitude_ch                               1637\n",
       "latitude_ch                                1634\n",
       "altitude                                    681\n",
       "arrival_delay_bucket_final                    3\n",
       "departure_delay_bucket_final                  3\n",
       "arrival_important_delay_bucket_final          3\n",
       "departure_important_delay_bucket_final        3\n",
       "outliers                                      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_zug.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering-out features not necessary for Input and Output of models\n",
    "\n",
    "* **Remove variable which have already been bucketed**\n",
    "    * arrival_time\n",
    "    * departure_time\n",
    "    * operating_day (replaced by 'operating_day_of_week')\n",
    "<br>\n",
    "* **Remove duplicate varibales**\n",
    "    * operator_name (keep operator_short)\n",
    "    * stop_name (keep stop_id)\n",
    "<br>\n",
    "* **Remove irrelavant varibles for classification taks**\n",
    "    * deviation_id\n",
    "    * transport_mode (as we focus on 'Zug' only)\n",
    "    * missing_ride_flag and add_ride_flag\n",
    "        * missing_ride_flag have been removed as considered as information potentially only available on last-minute - per-default (rides classified as 'important_delay')\n",
    "        * add_ride_flag have been kept as can be a relevant information to assess delay and probably planned ahead\n",
    "<br>\n",
    "* **Remove categorical variable with too high cardinality**\n",
    "    * ride_id\n",
    "    * line_id\n",
    "    * *(thinking of replacing Stop_id by city but decide to keep both for now)*\n",
    "<br>\n",
    "* **Remove variables which have been used to build target (and shouldn't be used in test set)**\n",
    "    * eta\n",
    "    * eta_status_clean\n",
    "    * arrival_delay_min\n",
    "    * etd\n",
    "    * etd_status_clean\n",
    "    * departure_delay_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_input = ['operating_day_of_week','operator_short','line_name','product_id','stop_id','arrival_time_of_day','departure_time_of_day','start_middle_end','provider_short','city','canton','longitude_ch','latitude_ch','altitude','transport_mode_stop']\n",
    "keep_input_cat = ['operating_day_of_week','operator_short','line_name','product_id','stop_id','arrival_time_of_day','departure_time_of_day','start_middle_end','provider_short','city','canton','transport_mode_stop']\n",
    "keep_output = ['arrival_delay_bucket_final','departure_delay_bucket_final','arrival_important_delay_bucket_final','departure_important_delay_bucket_final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "operating_day_of_week       1\n",
       "operator_short             44\n",
       "line_name                  93\n",
       "product_id                 17\n",
       "stop_id                  1667\n",
       "arrival_time_of_day         8\n",
       "departure_time_of_day       8\n",
       "start_middle_end            3\n",
       "provider_short             33\n",
       "city                      877\n",
       "canton                     26\n",
       "longitude_ch             1637\n",
       "latitude_ch              1634\n",
       "altitude                  681\n",
       "transport_mode_stop         8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_zug[keep_input].nunique()\n",
    "# thinking of removing stop_id, longitude_ch and latitude_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158121, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_zug[keep_output].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable transformation (one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158121, 2788)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df_merged_zug[keep_input], columns=keep_input_cat).shape\n",
    "# decide not to have k-1 columns per variable as I might be working with decision trees which need all columns. \n",
    "# would be fine using only k-1 columns for regression, SVMs or CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude_ch</th>\n",
       "      <th>latitude_ch</th>\n",
       "      <th>altitude</th>\n",
       "      <th>operating_day_of_week_Thursday</th>\n",
       "      <th>operator_short_AB-ab</th>\n",
       "      <th>operator_short_ASM-bti</th>\n",
       "      <th>operator_short_ASM-rvo</th>\n",
       "      <th>operator_short_ASM-snb</th>\n",
       "      <th>operator_short_AVA-bd</th>\n",
       "      <th>operator_short_AVA-wsb</th>\n",
       "      <th>...</th>\n",
       "      <th>canton_ZG</th>\n",
       "      <th>canton_ZH</th>\n",
       "      <th>transport_mode_stop_Unbekannt</th>\n",
       "      <th>transport_mode_stop_Zahnradbahn</th>\n",
       "      <th>transport_mode_stop_Zug</th>\n",
       "      <th>transport_mode_stop_Zug_Bus</th>\n",
       "      <th>transport_mode_stop_Zug_Bus_Tram</th>\n",
       "      <th>transport_mode_stop_Zug_Kabinenbahn</th>\n",
       "      <th>transport_mode_stop_Zug_Metro</th>\n",
       "      <th>transport_mode_stop_Zug_Tram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.61266e+06</td>\n",
       "      <td>1.26852e+06</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.61266e+06</td>\n",
       "      <td>1.26852e+06</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.61266e+06</td>\n",
       "      <td>1.26852e+06</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.61266e+06</td>\n",
       "      <td>1.26852e+06</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.61266e+06</td>\n",
       "      <td>1.26852e+06</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2788 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  longitude_ch  latitude_ch altitude  operating_day_of_week_Thursday  \\\n",
       "0  2.61266e+06  1.26852e+06      263                               1   \n",
       "1  2.61266e+06  1.26852e+06      263                               1   \n",
       "2  2.61266e+06  1.26852e+06      263                               1   \n",
       "3  2.61266e+06  1.26852e+06      263                               1   \n",
       "4  2.61266e+06  1.26852e+06      263                               1   \n",
       "\n",
       "   operator_short_AB-ab  operator_short_ASM-bti  operator_short_ASM-rvo  \\\n",
       "0                     0                       0                       0   \n",
       "1                     0                       0                       0   \n",
       "2                     0                       0                       0   \n",
       "3                     0                       0                       0   \n",
       "4                     0                       0                       0   \n",
       "\n",
       "   operator_short_ASM-snb  operator_short_AVA-bd  operator_short_AVA-wsb  ...  \\\n",
       "0                       0                      0                       0  ...   \n",
       "1                       0                      0                       0  ...   \n",
       "2                       0                      0                       0  ...   \n",
       "3                       0                      0                       0  ...   \n",
       "4                       0                      0                       0  ...   \n",
       "\n",
       "   canton_ZG  canton_ZH  transport_mode_stop_Unbekannt  \\\n",
       "0          0          0                              0   \n",
       "1          0          0                              0   \n",
       "2          0          0                              0   \n",
       "3          0          0                              0   \n",
       "4          0          0                              0   \n",
       "\n",
       "   transport_mode_stop_Zahnradbahn  transport_mode_stop_Zug  \\\n",
       "0                                0                        1   \n",
       "1                                0                        1   \n",
       "2                                0                        1   \n",
       "3                                0                        1   \n",
       "4                                0                        1   \n",
       "\n",
       "   transport_mode_stop_Zug_Bus  transport_mode_stop_Zug_Bus_Tram  \\\n",
       "0                            0                                 0   \n",
       "1                            0                                 0   \n",
       "2                            0                                 0   \n",
       "3                            0                                 0   \n",
       "4                            0                                 0   \n",
       "\n",
       "   transport_mode_stop_Zug_Kabinenbahn  transport_mode_stop_Zug_Metro  \\\n",
       "0                                    0                              0   \n",
       "1                                    0                              0   \n",
       "2                                    0                              0   \n",
       "3                                    0                              0   \n",
       "4                                    0                              0   \n",
       "\n",
       "   transport_mode_stop_Zug_Tram  \n",
       "0                             0  \n",
       "1                             0  \n",
       "2                             0  \n",
       "3                             0  \n",
       "4                             0  \n",
       "\n",
       "[5 rows x 2788 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df_merged_zug[keep_input], columns=keep_input_cat).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import training, validation and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_days = []\n",
    "for tr in np.arange(1,15):\n",
    "    #print(str(tr).zfill(2))\n",
    "    training_days.append(str(tr).zfill(2))\n",
    "validation_days = []\n",
    "for va in np.arange(15,22):\n",
    "    #print(str(va).zfill(2))\n",
    "    validation_days.append(str(va).zfill(2))\n",
    "test_days = []\n",
    "for te in np.arange(22,29):\n",
    "    #print(str(te).zfill(2))\n",
    "    test_days.append(str(te).zfill(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1854124, 21)\n",
      "(157983, 21)\n",
      "Shape final: (157983, 21)\n",
      "1\n",
      "(1873590, 21)\n",
      "(154120, 21)\n",
      "Shape final: (312103, 21)\n",
      "2\n",
      "(1511048, 21)\n",
      "(147614, 21)\n",
      "Shape final: (459717, 21)\n",
      "3\n",
      "(1138020, 21)\n",
      "(138283, 21)\n",
      "Shape final: (598000, 21)\n",
      "4\n",
      "(1863830, 21)\n",
      "(156951, 21)\n",
      "Shape final: (754951, 21)\n",
      "5\n",
      "(1860703, 21)\n",
      "(157711, 21)\n",
      "Shape final: (912662, 21)\n",
      "6\n",
      "(1852875, 21)\n",
      "(157790, 21)\n",
      "Shape final: (1070452, 21)\n",
      "7\n",
      "(1864414, 21)\n",
      "(157690, 21)\n",
      "Shape final: (1228142, 21)\n",
      "8\n",
      "(1885718, 21)\n",
      "(158600, 21)\n",
      "Shape final: (1386742, 21)\n",
      "9\n",
      "(1502261, 21)\n",
      "(146548, 21)\n",
      "Shape final: (1533290, 21)\n",
      "10\n",
      "(1127607, 21)\n",
      "(136232, 21)\n",
      "Shape final: (1669522, 21)\n",
      "11\n",
      "(1859314, 21)\n",
      "(156781, 21)\n",
      "Shape final: (1826303, 21)\n",
      "12\n",
      "(1855882, 21)\n",
      "(156385, 21)\n",
      "Shape final: (1982688, 21)\n",
      "13\n",
      "(1867644, 21)\n",
      "(155639, 21)\n",
      "Shape final: (2138327, 21)\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "d = 0\n",
    "zf = zipfile.ZipFile('20_10.zip') \n",
    "for x in training_days:\n",
    "    temp = pd.read_csv(zf.open('20_10/2020-10-' + x + '_istdaten.csv'),delimiter=';',low_memory=False) # import data for single day (1st October) for \n",
    "    print(temp.shape)\n",
    "    temp_2 = temp[temp['PRODUKT_ID'] == 'Zug']\n",
    "    print(temp_2.shape)\n",
    "    d = d + 1\n",
    "    if d == 1:\n",
    "        df_train = temp_2\n",
    "    else: \n",
    "        df_train = pd.concat([df_train,temp_2])\n",
    "    print('Shape final:',df_train.shape)\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1859473, 21)\n",
      "(156386, 21)\n",
      "Shape final: (156386, 21)\n",
      "1\n",
      "(1886155, 21)\n",
      "(157366, 21)\n",
      "Shape final: (313752, 21)\n",
      "2\n",
      "(1506195, 21)\n",
      "(147185, 21)\n",
      "Shape final: (460937, 21)\n",
      "3\n",
      "(1129869, 21)\n",
      "(138045, 21)\n",
      "Shape final: (598982, 21)\n",
      "4\n",
      "(1829842, 21)\n",
      "(157087, 21)\n",
      "Shape final: (756069, 21)\n",
      "5\n",
      "(1833200, 21)\n",
      "(156946, 21)\n",
      "Shape final: (913015, 21)\n",
      "6\n",
      "(1823739, 21)\n",
      "(156784, 21)\n",
      "Shape final: (1069799, 21)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "d_va = 0\n",
    "zf = zipfile.ZipFile('20_10.zip') \n",
    "for x in validation_days:\n",
    "    temp_va = pd.read_csv(zf.open('20_10/2020-10-' + x + '_istdaten.csv'),delimiter=';',low_memory=False) # import data for single day (1st October) for \n",
    "    print(temp_va.shape)\n",
    "    temp_va_2 = temp_va[temp_va['PRODUKT_ID'] == 'Zug']\n",
    "    print(temp_va_2.shape)\n",
    "    d_va = d_va + 1\n",
    "    if d_va == 1:\n",
    "        df_valid = temp_va_2\n",
    "    else: df_valid = pd.concat([df_valid,temp_va_2])\n",
    "    print('Shape final:',df_valid.shape)\n",
    "    print(d_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1827837, 21)\n",
      "(156833, 21)\n",
      "Shape final: (156833, 21)\n",
      "1\n",
      "(1857399, 21)\n",
      "(158581, 21)\n",
      "Shape final: (315414, 21)\n",
      "2\n",
      "(1475704, 21)\n",
      "(148250, 21)\n",
      "Shape final: (463664, 21)\n",
      "3\n",
      "(1118470, 21)\n",
      "(138054, 21)\n",
      "Shape final: (601718, 21)\n",
      "4\n",
      "(1852126, 21)\n",
      "(157393, 21)\n",
      "Shape final: (759111, 21)\n",
      "5\n",
      "(1860713, 21)\n",
      "(157416, 21)\n",
      "Shape final: (916527, 21)\n",
      "6\n",
      "(1874026, 21)\n",
      "(157448, 21)\n",
      "Shape final: (1073975, 21)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "d_te = 0\n",
    "zf = zipfile.ZipFile('20_10.zip') \n",
    "for x in test_days:\n",
    "    temp_te = pd.read_csv(zf.open('20_10/2020-10-' + x + '_istdaten.csv'),delimiter=';',low_memory=False) # import data for single day (1st October) for \n",
    "    print(temp_te.shape)\n",
    "    temp_te_2 = temp_te[temp_te['PRODUKT_ID'] == 'Zug']\n",
    "    print(temp_te_2.shape)\n",
    "    d_te = d_te + 1\n",
    "    if d_te == 1:\n",
    "        df_test = temp_te_2\n",
    "    else: df_test = pd.concat([df_test,temp_te_2])\n",
    "    print('Shape final:',df_test.shape)\n",
    "    print(d_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2138327, 21)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1069799, 21)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1073975, 21)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and transforming data as per EDA <a name='index'/>\n",
    "1. **Renaming columns** - <a href=#rename>here</a>\n",
    "2. **Update data types** - <a href=#dtypes>here</a>\n",
    "3. **Handling Null values** - <a href=#null>here</a>\n",
    "<br>    a. Stops name\n",
    "<br>    b. Product id\n",
    "4. **Feature engineering** - <a href=#engineer>here</a>\n",
    "<br>    a. Ride sequence (start_middle_end flag)\n",
    "<br>    b. ETA/ETD\n",
    "<br>    c. Time of day\n",
    "<br>    d. Delays\n",
    "5. **Final data sets** - <a href=#final>here</a>\n",
    "<br>    a. filtering-in only relevant features\n",
    "<br>    b. merging both data sets\n",
    "<br>    c. splitting for departure and arrival delays predictions\n",
    "6. **Data transformation to feed ML models** - <a href=#trans>here</a>\n",
    "<br>    a. Input features (categorical, numerical, merged)\n",
    "<br>    b. Output features\n",
    "7. **Saving data** - <a href=#save>here</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01.10.2020', '02.10.2020', '03.10.2020', '04.10.2020',\n",
       "       '05.10.2020', '06.10.2020', '07.10.2020', '08.10.2020',\n",
       "       '09.10.2020', '10.10.2020', '11.10.2020', '12.10.2020',\n",
       "       '13.10.2020', '14.10.2020'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['BETRIEBSTAG'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) translating columns naming from german to english** <a name='rename'/> | <a href=#index>Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['operating_day', 'ride_id', 'operator_id', 'operator_short',\n",
      "       'operator_name', 'transport_mode', 'line_id', 'line_name',\n",
      "       'deviation_id', 'product_id', 'add_ride_flag', 'missing_ride_flag',\n",
      "       'stop_id', 'stop_name', 'arrival_time', 'eta', 'eta_status',\n",
      "       'departure_time', 'etd', 'etd_status', 'ride_through_flag'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## Training\n",
    "df_train.rename(columns={'BETRIEBSTAG':'operating_day','FAHRT_BEZEICHNER':'ride_id','BETREIBER_ID':'operator_id','BETREIBER_ABK':'operator_short','BETREIBER_NAME':'operator_name',\\\n",
    "                   'PRODUKT_ID':'transport_mode','LINIEN_ID':'line_id','LINIEN_TEXT':'line_name','UMLAUF_ID':'deviation_id','VERKEHRSMITTEL_TEXT':'product_id','ZUSATZFAHRT_TF':'add_ride_flag',\\\n",
    "                  'FAELLT_AUS_TF':'missing_ride_flag','BPUIC':'stop_id','HALTESTELLEN_NAME':'stop_name','ANKUNFTSZEIT':'arrival_time','AN_PROGNOSE':'eta','AN_PROGNOSE_STATUS':'eta_status'\\\n",
    "                   ,'ABFAHRTSZEIT':'departure_time','AB_PROGNOSE':'etd','AB_PROGNOSE_STATUS':'etd_status','DURCHFAHRT_TF':'ride_through_flag'}, inplace=True)\n",
    "print(df_train.columns)\n",
    "\n",
    "## Validation\n",
    "df_valid.rename(columns={'BETRIEBSTAG':'operating_day','FAHRT_BEZEICHNER':'ride_id','BETREIBER_ID':'operator_id','BETREIBER_ABK':'operator_short','BETREIBER_NAME':'operator_name',\\\n",
    "                   'PRODUKT_ID':'transport_mode','LINIEN_ID':'line_id','LINIEN_TEXT':'line_name','UMLAUF_ID':'deviation_id','VERKEHRSMITTEL_TEXT':'product_id','ZUSATZFAHRT_TF':'add_ride_flag',\\\n",
    "                  'FAELLT_AUS_TF':'missing_ride_flag','BPUIC':'stop_id','HALTESTELLEN_NAME':'stop_name','ANKUNFTSZEIT':'arrival_time','AN_PROGNOSE':'eta','AN_PROGNOSE_STATUS':'eta_status'\\\n",
    "                   ,'ABFAHRTSZEIT':'departure_time','AB_PROGNOSE':'etd','AB_PROGNOSE_STATUS':'etd_status','DURCHFAHRT_TF':'ride_through_flag'}, inplace=True)\n",
    "\n",
    "## Test\n",
    "df_test.rename(columns={'BETRIEBSTAG':'operating_day','FAHRT_BEZEICHNER':'ride_id','BETREIBER_ID':'operator_id','BETREIBER_ABK':'operator_short','BETREIBER_NAME':'operator_name',\\\n",
    "                   'PRODUKT_ID':'transport_mode','LINIEN_ID':'line_id','LINIEN_TEXT':'line_name','UMLAUF_ID':'deviation_id','VERKEHRSMITTEL_TEXT':'product_id','ZUSATZFAHRT_TF':'add_ride_flag',\\\n",
    "                  'FAELLT_AUS_TF':'missing_ride_flag','BPUIC':'stop_id','HALTESTELLEN_NAME':'stop_name','ANKUNFTSZEIT':'arrival_time','AN_PROGNOSE':'eta','AN_PROGNOSE_STATUS':'eta_status'\\\n",
    "                   ,'ABFAHRTSZEIT':'departure_time','AB_PROGNOSE':'etd','AB_PROGNOSE_STATUS':'etd_status','DURCHFAHRT_TF':'ride_through_flag'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) update data types** <a name='dtypes'/> | <a href=#index>Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "## Training\n",
    "df_train['operating_day'] = pd.to_datetime(df_train['operating_day'], format=\"%d.%m.%Y\")\n",
    "df_train['arrival_time'] = pd.to_datetime(df_train['arrival_time'], format=\"%d.%m.%Y %H:%M\")\n",
    "df_train['departure_time'] = pd.to_datetime(df_train['departure_time'], format=\"%d.%m.%Y %H:%M\")\n",
    "df_train['eta'] = pd.to_datetime(df_train['eta'], format=\"%d.%m.%Y %H:%M:%S\")\n",
    "df_train['etd'] = pd.to_datetime(df_train['etd'], format=\"%d.%m.%Y %H:%M:%S\")\n",
    "# integer to string\n",
    "df_train['stop_id'] = df_train['stop_id'].astype(str)\n",
    "\n",
    "## Validation\n",
    "df_valid['operating_day'] = pd.to_datetime(df_valid['operating_day'], format=\"%d.%m.%Y\")\n",
    "df_valid['arrival_time'] = pd.to_datetime(df_valid['arrival_time'], format=\"%d.%m.%Y %H:%M\")\n",
    "df_valid['departure_time'] = pd.to_datetime(df_valid['departure_time'], format=\"%d.%m.%Y %H:%M\")\n",
    "df_valid['eta'] = pd.to_datetime(df_valid['eta'], format=\"%d.%m.%Y %H:%M:%S\")\n",
    "df_valid['etd'] = pd.to_datetime(df_valid['etd'], format=\"%d.%m.%Y %H:%M:%S\")\n",
    "# integer to string\n",
    "df_valid['stop_id'] = df_valid['stop_id'].astype(str)\n",
    "\n",
    "## Test\n",
    "df_test['operating_day'] = pd.to_datetime(df_test['operating_day'], format=\"%d.%m.%Y\")\n",
    "df_test['arrival_time'] = pd.to_datetime(df_test['arrival_time'], format=\"%d.%m.%Y %H:%M\")\n",
    "df_test['departure_time'] = pd.to_datetime(df_test['departure_time'], format=\"%d.%m.%Y %H:%M\")\n",
    "df_test['eta'] = pd.to_datetime(df_test['eta'], format=\"%d.%m.%Y %H:%M:%S\")\n",
    "df_test['etd'] = pd.to_datetime(df_test['etd'], format=\"%d.%m.%Y %H:%M:%S\")\n",
    "# integer to string\n",
    "df_test['stop_id'] = df_test['stop_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) handling NULL values** <a name='null'/> | <a href=#index>Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop name\n",
    "## Training\n",
    "df_train_merged = df_train.merge(right=df_stops_clean[['stop_name','stop_id']], how='left', on=['stop_id'], suffixes=('','_bis'))\n",
    "df_train_merged['stop_name'].fillna(df_train_merged['stop_name_bis'], inplace=True)\n",
    "#print('Even after mapping, we still have {} empty \"stop_name\"'.format(df_train['stop_name'].isnull().sum()))\n",
    "df_train_merged['stop_name'].fillna('unknown', inplace=True)\n",
    "\n",
    "## Validation\n",
    "df_valid_merged = df_valid.merge(right=df_stops_clean[['stop_name','stop_id']], how='left', on=['stop_id'], suffixes=('','_bis'))\n",
    "df_valid_merged['stop_name'].fillna(df_valid_merged['stop_name_bis'], inplace=True)\n",
    "#print('Even after mapping, we still have {} empty \"stop_name\"'.format(df_train['stop_name'].isnull().sum()))\n",
    "df_valid_merged['stop_name'].fillna('unknown', inplace=True)\n",
    "\n",
    "## Test\n",
    "df_test_merged = df_test.merge(right=df_stops_clean[['stop_name','stop_id']], how='left', on=['stop_id'], suffixes=('','_bis'))\n",
    "df_test_merged['stop_name'].fillna(df_test_merged['stop_name_bis'], inplace=True)\n",
    "#print('Even after mapping, we still have {} empty \"stop_name\"'.format(df_train['stop_name'].isnull().sum()))\n",
    "df_test_merged['stop_name'].fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3b handling NULL values in product id\n",
    "## Training\n",
    "df_train_merged['product_id'].fillna(value='unkown', inplace=True)\n",
    "## Validation\n",
    "df_valid_merged['product_id'].fillna(value='unkown', inplace=True)\n",
    "## Test\n",
    "df_test_merged['product_id'].fillna(value='unkown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Feature engineering** <a name='engineer'/> | <a href=#index>Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4a create 'start_middle_end' flag\n",
    "def start_end(row):\n",
    "    if row['arrival_time'] is pd.NaT:\n",
    "        return 'start_trip'\n",
    "    if row['departure_time'] is pd.NaT:\n",
    "        return 'end_trip'\n",
    "    return 'middle_stop'\n",
    "\n",
    "## Training\n",
    "df_train_merged['start_middle_end'] = df_train_merged.apply(lambda row: start_end(row), axis=1)\n",
    "## Validation\n",
    "df_valid_merged['start_middle_end'] = df_valid_merged.apply(lambda row: start_end(row), axis=1)\n",
    "## Test\n",
    "df_test_merged['start_middle_end'] = df_test_merged.apply(lambda row: start_end(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4b clean 'ETA/ETD' features\n",
    "def start_status(row):\n",
    "    if row['arrival_time'] is pd.NaT:\n",
    "        return 'NA'\n",
    "    if row['eta'] is pd.NaT:\n",
    "        return 'UNKOWN'\n",
    "    return row['eta_status']\n",
    "\n",
    "## Training\n",
    "df_train_merged['eta_status_clean'] = df_train_merged.apply(lambda row: start_status(row), axis=1)\n",
    "df_train_merged['eta_status_clean'].replace({'GESCHAETZT':'ESTIMATED','UNBEKANNT':'ESTIMATED'}, inplace=True)\n",
    "## Validation\n",
    "df_valid_merged['eta_status_clean'] = df_valid_merged.apply(lambda row: start_status(row), axis=1)\n",
    "df_valid_merged['eta_status_clean'].replace({'GESCHAETZT':'ESTIMATED','UNBEKANNT':'ESTIMATED'}, inplace=True)\n",
    "## Test\n",
    "df_test_merged['eta_status_clean'] = df_test_merged.apply(lambda row: start_status(row), axis=1)\n",
    "df_test_merged['eta_status_clean'].replace({'GESCHAETZT':'ESTIMATED','UNBEKANNT':'ESTIMATED'}, inplace=True)\n",
    "\n",
    "def end_status(row):\n",
    "    if row['departure_time'] is pd.NaT:\n",
    "        return 'NA'\n",
    "    if row['etd'] is pd.NaT:\n",
    "        return 'UNKOWN'\n",
    "    return row['etd_status']\n",
    "\n",
    "## Training\n",
    "df_train_merged['etd_status_clean'] = df_train_merged.apply(lambda row: end_status(row), axis=1)\n",
    "df_train_merged['etd_status_clean'].replace({'GESCHAETZT':'ESTIMATED','UNBEKANNT':'ESTIMATED'}, inplace=True)\n",
    "## Validation\n",
    "df_valid_merged['etd_status_clean'] = df_valid_merged.apply(lambda row: end_status(row), axis=1)\n",
    "df_valid_merged['etd_status_clean'].replace({'GESCHAETZT':'ESTIMATED','UNBEKANNT':'ESTIMATED'}, inplace=True)\n",
    "## Test\n",
    "df_test_merged['etd_status_clean'] = df_test_merged.apply(lambda row: end_status(row), axis=1)\n",
    "df_test_merged['etd_status_clean'].replace({'GESCHAETZT':'ESTIMATED','UNBEKANNT':'ESTIMATED'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4c time_of_day\n",
    "## Training\n",
    "df_train_merged['departure_time_hour'] = df_train_merged['departure_time'].dt.hour\n",
    "df_train_merged['arrival_time_hour'] = df_train_merged['arrival_time'].dt.hour\n",
    "df_train_merged['operating_day_of_week'] = df_train_merged['operating_day'].dt.day_name()\n",
    "## Validation\n",
    "df_valid_merged['departure_time_hour'] = df_valid_merged['departure_time'].dt.hour\n",
    "df_valid_merged['arrival_time_hour'] = df_valid_merged['arrival_time'].dt.hour\n",
    "df_valid_merged['operating_day_of_week'] = df_valid_merged['operating_day'].dt.day_name()\n",
    "## Test\n",
    "df_test_merged['departure_time_hour'] = df_test_merged['departure_time'].dt.hour\n",
    "df_test_merged['arrival_time_hour'] = df_test_merged['arrival_time'].dt.hour\n",
    "df_test_merged['operating_day_of_week'] = df_test_merged['operating_day'].dt.day_name()\n",
    "\n",
    "def rush_hour_dep(row):\n",
    "    if row['departure_time'] is pd.NaT:\n",
    "        return 'na'\n",
    "    if row['departure_time_hour'] < 6:\n",
    "        return 'early_morning'\n",
    "    if row['departure_time_hour'] < 9:\n",
    "        return 'peak_morning'\n",
    "    if row['departure_time_hour'] < 12:\n",
    "        return 'morning'\n",
    "    if row['departure_time_hour'] < 14:\n",
    "        return 'midday'\n",
    "    if row['departure_time_hour'] < 16:\n",
    "        return 'afternoon'\n",
    "    if row['departure_time_hour'] < 20:\n",
    "        return 'peak_afternoon'\n",
    "    if row['departure_time_hour'] <= 24:\n",
    "        return 'evening'\n",
    "    return 'na'\n",
    "## Training\n",
    "df_train_merged['departure_time_of_day'] = df_train_merged.apply(lambda row: rush_hour_dep(row), axis=1)\n",
    "## Validation\n",
    "df_valid_merged['departure_time_of_day'] = df_valid_merged.apply(lambda row: rush_hour_dep(row), axis=1)\n",
    "## Test\n",
    "df_test_merged['departure_time_of_day'] = df_test_merged.apply(lambda row: rush_hour_dep(row), axis=1)\n",
    "\n",
    "def rush_hour_arr(row):\n",
    "    if row['arrival_time'] is pd.NaT:\n",
    "        return 'na'\n",
    "    if row['arrival_time_hour'] < 6:\n",
    "        return 'early_morning'\n",
    "    if row['arrival_time_hour'] < 9:\n",
    "        return 'peak_morning'\n",
    "    if row['arrival_time_hour'] < 12:\n",
    "        return 'morning'\n",
    "    if row['arrival_time_hour'] < 14:\n",
    "        return 'midday'\n",
    "    if row['arrival_time_hour'] < 16:\n",
    "        return 'afternoon'\n",
    "    if row['arrival_time_hour'] < 20:\n",
    "        return 'peak_afternoon'\n",
    "    if row['arrival_time_hour'] <= 24:\n",
    "        return 'evening'\n",
    "    return 'na'\n",
    "## Training\n",
    "df_train_merged['arrival_time_of_day'] = df_train_merged.apply(lambda row: rush_hour_arr(row), axis=1)\n",
    "## Validation\n",
    "df_valid_merged['arrival_time_of_day'] = df_valid_merged.apply(lambda row: rush_hour_arr(row), axis=1)\n",
    "## Test\n",
    "df_test_merged['arrival_time_of_day'] = df_test_merged.apply(lambda row: rush_hour_arr(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4d delays\n",
    "## Training\n",
    "df_train_merged['arrival_delay_min'] = round(((df_train_merged['eta'] - df_train_merged['arrival_time']).dt.total_seconds() / 60),0)\n",
    "df_train_merged['departure_delay_min'] = round(((df_train_merged['etd'] - df_train_merged['departure_time']).dt.total_seconds() / 60),0)\n",
    "## Validation\n",
    "df_valid_merged['arrival_delay_min'] = round(((df_valid_merged['eta'] - df_valid_merged['arrival_time']).dt.total_seconds() / 60),0)\n",
    "df_valid_merged['departure_delay_min'] = round(((df_valid_merged['etd'] - df_valid_merged['departure_time']).dt.total_seconds() / 60),0)\n",
    "## Test\n",
    "df_test_merged['arrival_delay_min'] = round(((df_test_merged['eta'] - df_test_merged['arrival_time']).dt.total_seconds() / 60),0)\n",
    "df_test_merged['departure_delay_min'] = round(((df_test_merged['etd'] - df_test_merged['departure_time']).dt.total_seconds() / 60),0)\n",
    "\n",
    "def delay_buckets_dep(row):\n",
    "    if row['departure_time'] is pd.NaT:\n",
    "        return 'na'\n",
    "    if row['missing_ride_flag'] == True: # adding criteria to deal with missing_ride_flag\n",
    "        return 'important_delay'\n",
    "    if row['etd'] is pd.NaT:\n",
    "        return 'unknown'\n",
    "    if row['departure_delay_min'] >= 5:\n",
    "        return 'important_delay'\n",
    "    if row['departure_delay_min'] >= 2:\n",
    "        return 'delay'\n",
    "    if row['departure_delay_min'] >= -1:\n",
    "        return 'on_time'\n",
    "    return 'early'\n",
    "## Training\n",
    "df_train_merged['departure_delay_bucket'] = df_train_merged.apply(lambda row: delay_buckets_dep(row), axis=1)\n",
    "## Validation\n",
    "df_valid_merged['departure_delay_bucket'] = df_valid_merged.apply(lambda row: delay_buckets_dep(row), axis=1)\n",
    "## Test\n",
    "df_test_merged['departure_delay_bucket'] = df_test_merged.apply(lambda row: delay_buckets_dep(row), axis=1)\n",
    "\n",
    "def delay_buckets_arr(row):\n",
    "    if row['arrival_time'] is pd.NaT:\n",
    "        return 'na'\n",
    "    if row['missing_ride_flag'] == True: # adding criteria to deal with missing ride_flag\n",
    "        return 'important_delay'\n",
    "    if row['eta'] is pd.NaT:\n",
    "        return 'unknown'\n",
    "    if row['arrival_delay_min'] >= 5:\n",
    "        return 'important_delay'\n",
    "    if row['arrival_delay_min'] >= 2:\n",
    "        return 'delay'\n",
    "    if row['arrival_delay_min'] >= -1:\n",
    "        return 'on_time'\n",
    "    return 'early'\n",
    "## Training\n",
    "df_train_merged['arrival_delay_bucket'] = df_train_merged.apply(lambda row: delay_buckets_arr(row), axis=1)\n",
    "## Validation\n",
    "df_valid_merged['arrival_delay_bucket'] = df_valid_merged.apply(lambda row: delay_buckets_arr(row), axis=1)\n",
    "## Test\n",
    "df_test_merged['arrival_delay_bucket'] = df_test_merged.apply(lambda row: delay_buckets_arr(row), axis=1)\n",
    "\n",
    "# plan to work with binary classifiers and therefore regroup target variables in binary classes (e.g.: 'no_delay','delay')\n",
    "# 'na' won't be in scope\n",
    "## Training\n",
    "df_train_merged['arrival_delay_bucket_final'] = df_train_merged['arrival_delay_bucket'].replace({'early':'no_delay','on_time':'no_delay','unknown':'no_delay','important_delay':'delay'})\n",
    "df_train_merged['departure_delay_bucket_final'] = df_train_merged['departure_delay_bucket'].replace({'early':'no_delay','on_time':'no_delay','unknown':'no_delay','important_delay':'delay'})\n",
    "df_train_merged['arrival_important_delay_bucket_final'] = df_train_merged['arrival_delay_bucket'].replace({'early':'no_delay','on_time':'no_delay','unknown':'no_delay','delay':'no_delay'})\n",
    "df_train_merged['departure_important_delay_bucket_final'] = df_train_merged['departure_delay_bucket'].replace({'early':'no_delay','on_time':'no_delay','unknown':'no_delay','delay':'no_delay'})\n",
    "## Validation\n",
    "df_valid_merged['arrival_delay_bucket_final'] = df_valid_merged['arrival_delay_bucket'].replace({'early':'no_delay','on_time':'no_delay','unknown':'no_delay','important_delay':'delay'})\n",
    "df_valid_merged['departure_delay_bucket_final'] = df_valid_merged['departure_delay_bucket'].replace({'early':'no_delay','on_time':'no_delay','unknown':'no_delay','important_delay':'delay'})\n",
    "df_valid_merged['arrival_important_delay_bucket_final'] = df_valid_merged['arrival_delay_bucket'].replace({'early':'no_delay','on_time':'no_delay','unknown':'no_delay','delay':'no_delay'})\n",
    "df_valid_merged['departure_important_delay_bucket_final'] = df_valid_merged['departure_delay_bucket'].replace({'early':'no_delay','on_time':'no_delay','unknown':'no_delay','delay':'no_delay'})\n",
    "## Test\n",
    "df_test_merged['arrival_delay_bucket_final'] = df_test_merged['arrival_delay_bucket'].replace({'early':'no_delay','on_time':'no_delay','unknown':'no_delay','important_delay':'delay'})\n",
    "df_test_merged['departure_delay_bucket_final'] = df_test_merged['departure_delay_bucket'].replace({'early':'no_delay','on_time':'no_delay','unknown':'no_delay','important_delay':'delay'})\n",
    "df_test_merged['arrival_important_delay_bucket_final'] = df_test_merged['arrival_delay_bucket'].replace({'early':'no_delay','on_time':'no_delay','unknown':'no_delay','delay':'no_delay'})\n",
    "df_test_merged['departure_important_delay_bucket_final'] = df_test_merged['departure_delay_bucket'].replace({'early':'no_delay','on_time':'no_delay','unknown':'no_delay','delay':'no_delay'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Final data sets** <a name='final'/> | <a href=#index>Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5a filtering-in only relevant features\n",
    "# could be using parameter here!\n",
    "## Training\n",
    "df_merged_train_clean = df_train_merged[['operating_day','operating_day_of_week','ride_id','operator_short','operator_name','transport_mode','line_id','line_name','deviation_id','product_id','add_ride_flag','missing_ride_flag','stop_id','stop_name',\\\n",
    "          'arrival_time','eta','eta_status_clean','arrival_time_of_day','arrival_delay_min','arrival_delay_bucket',\\\n",
    "            'departure_time','etd','etd_status_clean','departure_time_of_day','departure_delay_min','departure_delay_bucket','start_middle_end',\\\n",
    "            'arrival_delay_bucket_final','departure_delay_bucket_final','arrival_important_delay_bucket_final','departure_important_delay_bucket_final']]\n",
    "## Validation\n",
    "df_merged_valid_clean = df_valid_merged[['operating_day','operating_day_of_week','ride_id','operator_short','operator_name','transport_mode','line_id','line_name','deviation_id','product_id','add_ride_flag','missing_ride_flag','stop_id','stop_name',\\\n",
    "          'arrival_time','eta','eta_status_clean','arrival_time_of_day','arrival_delay_min','arrival_delay_bucket',\\\n",
    "            'departure_time','etd','etd_status_clean','departure_time_of_day','departure_delay_min','departure_delay_bucket','start_middle_end',\\\n",
    "            'arrival_delay_bucket_final','departure_delay_bucket_final','arrival_important_delay_bucket_final','departure_important_delay_bucket_final']]\n",
    "## Test\n",
    "df_merged_test_clean = df_test_merged[['operating_day','operating_day_of_week','ride_id','operator_short','operator_name','transport_mode','line_id','line_name','deviation_id','product_id','add_ride_flag','missing_ride_flag','stop_id','stop_name',\\\n",
    "          'arrival_time','eta','eta_status_clean','arrival_time_of_day','arrival_delay_min','arrival_delay_bucket',\\\n",
    "            'departure_time','etd','etd_status_clean','departure_time_of_day','departure_delay_min','departure_delay_bucket','start_middle_end',\\\n",
    "            'arrival_delay_bucket_final','departure_delay_bucket_final','arrival_important_delay_bucket_final','departure_important_delay_bucket_final']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5b merging both final dataframes\n",
    "## Training\n",
    "df_tr_clean = pd.merge(left=df_merged_train_clean, right=df_stops_clean[['stop_id','transport_mode','provider_short','city','canton','longitude_ch','latitude_ch','altitude']], how='left', on='stop_id', suffixes=('','_stop'))\n",
    "## Validation\n",
    "df_va_clean = pd.merge(left=df_merged_valid_clean, right=df_stops_clean[['stop_id','transport_mode','provider_short','city','canton','longitude_ch','latitude_ch','altitude']], how='left', on='stop_id', suffixes=('','_stop'))\n",
    "## Test\n",
    "df_te_clean = pd.merge(left=df_merged_test_clean, right=df_stops_clean[['stop_id','transport_mode','provider_short','city','canton','longitude_ch','latitude_ch','altitude']], how='left', on='stop_id', suffixes=('','_stop'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5c splitting final data sets\n",
    "# arrival set\n",
    "keep_input_arr = ['operating_day_of_week','operator_short','line_name','product_id','stop_id','arrival_time_of_day','start_middle_end','provider_short','city','canton','longitude_ch','latitude_ch','altitude','transport_mode_stop']\n",
    "keep_input_cat_arr = ['operating_day_of_week','operator_short','line_name','product_id','stop_id','arrival_time_of_day','start_middle_end','provider_short','city','canton','transport_mode_stop']\n",
    "keep_input_num_arr = ['longitude_ch','latitude_ch','altitude']\n",
    "keep_output_arr = ['arrival_delay_bucket_final','arrival_important_delay_bucket_final']\n",
    "\n",
    "## Training\n",
    "df_tr_arr = df_tr_clean[~(df_tr_clean['start_middle_end'] == 'start_trip')][(keep_input_arr+keep_output_arr)]\n",
    "## Validation\n",
    "df_va_arr = df_va_clean[~(df_va_clean['start_middle_end'] == 'start_trip')][(keep_input_arr+keep_output_arr)]\n",
    "## Test\n",
    "df_te_arr = df_te_clean[~(df_te_clean['start_middle_end'] == 'start_trip')][(keep_input_arr+keep_output_arr)]\n",
    "\n",
    "# departure set\n",
    "keep_input_dep = ['operating_day_of_week','operator_short','line_name','product_id','stop_id','departure_time_of_day','start_middle_end','provider_short','city','canton','longitude_ch','latitude_ch','altitude','transport_mode_stop']\n",
    "keep_input_cat_dep = ['operating_day_of_week','operator_short','line_name','product_id','stop_id','departure_time_of_day','start_middle_end','provider_short','city','canton','transport_mode_stop']\n",
    "keep_input_num_dep = ['longitude_ch','latitude_ch','altitude']\n",
    "keep_output_dep = ['departure_delay_bucket_final','departure_important_delay_bucket_final']\n",
    "\n",
    "## Training\n",
    "df_tr_dep = df_tr_clean[~(df_tr_clean['start_middle_end'] == 'end_trip')][(keep_input_dep+keep_output_dep)]\n",
    "## Validation\n",
    "df_va_dep = df_va_clean[~(df_va_clean['start_middle_end'] == 'end_trip')][(keep_input_dep+keep_output_dep)]\n",
    "## Test\n",
    "df_te_dep = df_te_clean[~(df_te_clean['start_middle_end'] == 'end_trip')][(keep_input_dep+keep_output_dep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training arrival set shape: (1948998, 16)\n",
      "Training departure set shape: (1948998, 16)\n",
      "Validation arrival set shape: (974789, 16)\n",
      "Validation departure set shape: (974789, 16)\n",
      "Test arrival set shape: (978361, 16)\n",
      "Test departure set shape: (978361, 16)\n"
     ]
    }
   ],
   "source": [
    "print('Training arrival set shape:',df_tr_arr.shape)\n",
    "print('Training departure set shape:',df_tr_arr.shape)\n",
    "print('Validation arrival set shape:',df_va_arr.shape)\n",
    "print('Validation departure set shape:',df_va_arr.shape)\n",
    "print('Test arrival set shape:',df_te_arr.shape)\n",
    "print('Test departure set shape:',df_te_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>operating_day_of_week</th>\n",
       "      <th>operator_short</th>\n",
       "      <th>line_name</th>\n",
       "      <th>product_id</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>arrival_time_of_day</th>\n",
       "      <th>start_middle_end</th>\n",
       "      <th>provider_short</th>\n",
       "      <th>city</th>\n",
       "      <th>canton</th>\n",
       "      <th>longitude_ch</th>\n",
       "      <th>latitude_ch</th>\n",
       "      <th>altitude</th>\n",
       "      <th>transport_mode_stop</th>\n",
       "      <th>arrival_delay_bucket_final</th>\n",
       "      <th>arrival_important_delay_bucket_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>DB</td>\n",
       "      <td>RE</td>\n",
       "      <td>RE</td>\n",
       "      <td>8500090</td>\n",
       "      <td>peak_morning</td>\n",
       "      <td>end_trip</td>\n",
       "      <td>DICH</td>\n",
       "      <td>Basel</td>\n",
       "      <td>BS</td>\n",
       "      <td>2612665</td>\n",
       "      <td>1268525</td>\n",
       "      <td>263</td>\n",
       "      <td>Zug</td>\n",
       "      <td>no_delay</td>\n",
       "      <td>no_delay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>DB</td>\n",
       "      <td>RE</td>\n",
       "      <td>RE</td>\n",
       "      <td>8500090</td>\n",
       "      <td>peak_morning</td>\n",
       "      <td>end_trip</td>\n",
       "      <td>DICH</td>\n",
       "      <td>Basel</td>\n",
       "      <td>BS</td>\n",
       "      <td>2612665</td>\n",
       "      <td>1268525</td>\n",
       "      <td>263</td>\n",
       "      <td>Zug</td>\n",
       "      <td>no_delay</td>\n",
       "      <td>no_delay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>DB</td>\n",
       "      <td>RE</td>\n",
       "      <td>RE</td>\n",
       "      <td>8500090</td>\n",
       "      <td>morning</td>\n",
       "      <td>end_trip</td>\n",
       "      <td>DICH</td>\n",
       "      <td>Basel</td>\n",
       "      <td>BS</td>\n",
       "      <td>2612665</td>\n",
       "      <td>1268525</td>\n",
       "      <td>263</td>\n",
       "      <td>Zug</td>\n",
       "      <td>no_delay</td>\n",
       "      <td>no_delay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>DB</td>\n",
       "      <td>RE</td>\n",
       "      <td>RE</td>\n",
       "      <td>8500090</td>\n",
       "      <td>morning</td>\n",
       "      <td>end_trip</td>\n",
       "      <td>DICH</td>\n",
       "      <td>Basel</td>\n",
       "      <td>BS</td>\n",
       "      <td>2612665</td>\n",
       "      <td>1268525</td>\n",
       "      <td>263</td>\n",
       "      <td>Zug</td>\n",
       "      <td>delay</td>\n",
       "      <td>no_delay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>DB</td>\n",
       "      <td>RE</td>\n",
       "      <td>RE</td>\n",
       "      <td>8500090</td>\n",
       "      <td>morning</td>\n",
       "      <td>end_trip</td>\n",
       "      <td>DICH</td>\n",
       "      <td>Basel</td>\n",
       "      <td>BS</td>\n",
       "      <td>2612665</td>\n",
       "      <td>1268525</td>\n",
       "      <td>263</td>\n",
       "      <td>Zug</td>\n",
       "      <td>delay</td>\n",
       "      <td>important_delay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  operating_day_of_week operator_short line_name product_id  stop_id  \\\n",
       "0              Thursday             DB        RE         RE  8500090   \n",
       "1              Thursday             DB        RE         RE  8500090   \n",
       "2              Thursday             DB        RE         RE  8500090   \n",
       "4              Thursday             DB        RE         RE  8500090   \n",
       "6              Thursday             DB        RE         RE  8500090   \n",
       "\n",
       "  arrival_time_of_day start_middle_end provider_short   city canton  \\\n",
       "0        peak_morning         end_trip           DICH  Basel     BS   \n",
       "1        peak_morning         end_trip           DICH  Basel     BS   \n",
       "2             morning         end_trip           DICH  Basel     BS   \n",
       "4             morning         end_trip           DICH  Basel     BS   \n",
       "6             morning         end_trip           DICH  Basel     BS   \n",
       "\n",
       "  longitude_ch latitude_ch altitude transport_mode_stop  \\\n",
       "0      2612665     1268525      263                 Zug   \n",
       "1      2612665     1268525      263                 Zug   \n",
       "2      2612665     1268525      263                 Zug   \n",
       "4      2612665     1268525      263                 Zug   \n",
       "6      2612665     1268525      263                 Zug   \n",
       "\n",
       "  arrival_delay_bucket_final arrival_important_delay_bucket_final  \n",
       "0                   no_delay                             no_delay  \n",
       "1                   no_delay                             no_delay  \n",
       "2                   no_delay                             no_delay  \n",
       "4                      delay                             no_delay  \n",
       "6                      delay                      important_delay  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr_arr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>operating_day_of_week</th>\n",
       "      <th>operator_short</th>\n",
       "      <th>line_name</th>\n",
       "      <th>product_id</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>departure_time_of_day</th>\n",
       "      <th>start_middle_end</th>\n",
       "      <th>provider_short</th>\n",
       "      <th>city</th>\n",
       "      <th>canton</th>\n",
       "      <th>longitude_ch</th>\n",
       "      <th>latitude_ch</th>\n",
       "      <th>altitude</th>\n",
       "      <th>transport_mode_stop</th>\n",
       "      <th>departure_delay_bucket_final</th>\n",
       "      <th>departure_important_delay_bucket_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>DB</td>\n",
       "      <td>RE</td>\n",
       "      <td>RE</td>\n",
       "      <td>8500090</td>\n",
       "      <td>peak_morning</td>\n",
       "      <td>start_trip</td>\n",
       "      <td>DICH</td>\n",
       "      <td>Basel</td>\n",
       "      <td>BS</td>\n",
       "      <td>2612665</td>\n",
       "      <td>1268525</td>\n",
       "      <td>263</td>\n",
       "      <td>Zug</td>\n",
       "      <td>no_delay</td>\n",
       "      <td>no_delay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>DB</td>\n",
       "      <td>RE</td>\n",
       "      <td>RE</td>\n",
       "      <td>8500090</td>\n",
       "      <td>peak_morning</td>\n",
       "      <td>start_trip</td>\n",
       "      <td>DICH</td>\n",
       "      <td>Basel</td>\n",
       "      <td>BS</td>\n",
       "      <td>2612665</td>\n",
       "      <td>1268525</td>\n",
       "      <td>263</td>\n",
       "      <td>Zug</td>\n",
       "      <td>delay</td>\n",
       "      <td>important_delay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>DB</td>\n",
       "      <td>RE</td>\n",
       "      <td>RE</td>\n",
       "      <td>8500090</td>\n",
       "      <td>peak_morning</td>\n",
       "      <td>start_trip</td>\n",
       "      <td>DICH</td>\n",
       "      <td>Basel</td>\n",
       "      <td>BS</td>\n",
       "      <td>2612665</td>\n",
       "      <td>1268525</td>\n",
       "      <td>263</td>\n",
       "      <td>Zug</td>\n",
       "      <td>no_delay</td>\n",
       "      <td>no_delay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>DB</td>\n",
       "      <td>RE</td>\n",
       "      <td>RE</td>\n",
       "      <td>8500090</td>\n",
       "      <td>morning</td>\n",
       "      <td>start_trip</td>\n",
       "      <td>DICH</td>\n",
       "      <td>Basel</td>\n",
       "      <td>BS</td>\n",
       "      <td>2612665</td>\n",
       "      <td>1268525</td>\n",
       "      <td>263</td>\n",
       "      <td>Zug</td>\n",
       "      <td>delay</td>\n",
       "      <td>no_delay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>DB</td>\n",
       "      <td>RE</td>\n",
       "      <td>RE</td>\n",
       "      <td>8500090</td>\n",
       "      <td>morning</td>\n",
       "      <td>start_trip</td>\n",
       "      <td>DICH</td>\n",
       "      <td>Basel</td>\n",
       "      <td>BS</td>\n",
       "      <td>2612665</td>\n",
       "      <td>1268525</td>\n",
       "      <td>263</td>\n",
       "      <td>Zug</td>\n",
       "      <td>no_delay</td>\n",
       "      <td>no_delay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   operating_day_of_week operator_short line_name product_id  stop_id  \\\n",
       "3               Thursday             DB        RE         RE  8500090   \n",
       "5               Thursday             DB        RE         RE  8500090   \n",
       "7               Thursday             DB        RE         RE  8500090   \n",
       "8               Thursday             DB        RE         RE  8500090   \n",
       "10              Thursday             DB        RE         RE  8500090   \n",
       "\n",
       "   departure_time_of_day start_middle_end provider_short   city canton  \\\n",
       "3           peak_morning       start_trip           DICH  Basel     BS   \n",
       "5           peak_morning       start_trip           DICH  Basel     BS   \n",
       "7           peak_morning       start_trip           DICH  Basel     BS   \n",
       "8                morning       start_trip           DICH  Basel     BS   \n",
       "10               morning       start_trip           DICH  Basel     BS   \n",
       "\n",
       "   longitude_ch latitude_ch altitude transport_mode_stop  \\\n",
       "3       2612665     1268525      263                 Zug   \n",
       "5       2612665     1268525      263                 Zug   \n",
       "7       2612665     1268525      263                 Zug   \n",
       "8       2612665     1268525      263                 Zug   \n",
       "10      2612665     1268525      263                 Zug   \n",
       "\n",
       "   departure_delay_bucket_final departure_important_delay_bucket_final  \n",
       "3                      no_delay                               no_delay  \n",
       "5                         delay                        important_delay  \n",
       "7                      no_delay                               no_delay  \n",
       "8                         delay                               no_delay  \n",
       "10                     no_delay                               no_delay  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr_dep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6) Data transformation to feed models** <a name='trans'/> | <a href=#index>Back to top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrival set\n",
    "canton = 'VD' # choose which canton to focus on\n",
    "df_tr_arr_cant = df_tr_arr[df_tr_arr['canton'] == canton]\n",
    "df_va_arr_cant = df_va_arr[df_va_arr['canton'] == canton]\n",
    "df_te_arr_cant = df_te_arr[df_te_arr['canton'] == canton]\n",
    "\n",
    "# departure set\n",
    "df_tr_dep_cant = df_tr_dep[df_tr_dep['canton'] == canton]\n",
    "df_va_dep_cant = df_va_dep[df_va_dep['canton'] == canton]\n",
    "df_te_dep_cant = df_te_dep[df_te_dep['canton'] == canton]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape training arrival: (215050, 16)\n",
      "Shape validation arrival: (108720, 16)\n",
      "Shape test arrival: (107366, 16)\n",
      "***\n",
      "Shape training departure: (215023, 16)\n",
      "Shape validation departure: (108689, 16)\n",
      "Shape test departure: (107323, 16)\n"
     ]
    }
   ],
   "source": [
    "print('Shape training arrival:',df_tr_arr_cant.shape)\n",
    "print('Shape validation arrival:',df_va_arr_cant.shape)\n",
    "print('Shape test arrival:',df_te_arr_cant.shape)\n",
    "print('***')\n",
    "print('Shape training departure:',df_tr_dep_cant.shape)\n",
    "print('Shape validation departure:',df_va_dep_cant.shape)\n",
    "print('Shape test departure:',df_te_dep_cant.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape training arrival (cat): (215050, 434)\n",
      "Shape validation arrival (cat): (108720, 424)\n",
      "Shape test arrival (cat): (107366, 424)\n",
      "***\n",
      "Shape training departure (cat): (215023, 434)\n",
      "Shape validation departure (cat): (108689, 424)\n",
      "Shape test departure (cat): (107323, 424)\n"
     ]
    }
   ],
   "source": [
    "# arrival set\n",
    "## Training\n",
    "df_tr_arr_cat = pd.get_dummies(df_tr_arr_cant[keep_input_arr], columns=keep_input_cat_arr)\n",
    "print('Shape training arrival (cat):',df_tr_arr_cat.shape)\n",
    "## Validation\n",
    "df_va_arr_cat = pd.get_dummies(df_va_arr_cant[keep_input_arr], columns=keep_input_cat_arr)\n",
    "print('Shape validation arrival (cat):',df_va_arr_cat.shape)\n",
    "## Test\n",
    "df_te_arr_cat = pd.get_dummies(df_te_arr_cant[keep_input_arr], columns=keep_input_cat_arr)\n",
    "print('Shape test arrival (cat):',df_te_arr_cat.shape)\n",
    "\n",
    "print('***')\n",
    "# departure set\n",
    "## Training\n",
    "df_tr_dep_cat = pd.get_dummies(df_tr_dep_cant[keep_input_dep], columns=keep_input_cat_dep)\n",
    "print('Shape training departure (cat):',df_tr_dep_cat.shape)\n",
    "## Validation\n",
    "df_va_dep_cat = pd.get_dummies(df_va_dep_cant[keep_input_dep], columns=keep_input_cat_dep)\n",
    "print('Shape validation departure (cat):',df_va_dep_cat.shape)\n",
    "## Test\n",
    "df_te_dep_cat = pd.get_dummies(df_te_dep_cant[keep_input_dep], columns=keep_input_cat_dep)\n",
    "print('Shape test departure (cat):',df_te_dep_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape training arrival (num): (215050, 3)\n",
      "Shape validation arrival (num): (108720, 3)\n",
      "Shape test arrival (num): (107366, 3)\n",
      "***\n",
      "Shape training departure (num): (215023, 3)\n",
      "Shape validation departure (num): (108689, 3)\n",
      "Shape test departure (num): (107323, 3)\n"
     ]
    }
   ],
   "source": [
    "# arrival set\n",
    "scaler_arr = StandardScaler()\n",
    "## Training\n",
    "num_tr_arr = pd.DataFrame(scaler_arr.fit_transform(X=df_tr_arr_cant[keep_input_num_arr]), columns=keep_input_num_arr)\n",
    "print('Shape training arrival (num):',num_tr_arr.shape)\n",
    "## Validation\n",
    "num_va_arr = pd.DataFrame(scaler_arr.transform(X=df_va_arr_cant[keep_input_num_arr]), columns=keep_input_num_arr)\n",
    "print('Shape validation arrival (num):',num_va_arr.shape)\n",
    "## Test\n",
    "num_te_arr = pd.DataFrame(scaler_arr.transform(X=df_te_arr_cant[keep_input_num_arr]), columns=keep_input_num_arr)\n",
    "print('Shape test arrival (num):',num_te_arr.shape)\n",
    "print('***')\n",
    "# departure set\n",
    "scaler_dep = StandardScaler()\n",
    "## Training\n",
    "num_tr_dep = pd.DataFrame(scaler_dep.fit_transform(X=df_tr_dep_cant[keep_input_num_dep]), columns=keep_input_num_dep)\n",
    "print('Shape training departure (num):',num_tr_dep.shape)\n",
    "## Validation\n",
    "num_va_dep = pd.DataFrame(scaler_dep.transform(X=df_va_dep_cant[keep_input_num_dep]), columns=keep_input_num_dep)\n",
    "print('Shape validation departure (num):',num_va_dep.shape)\n",
    "## Test\n",
    "num_te_dep = pd.DataFrame(scaler_dep.transform(X=df_te_dep_cant[keep_input_num_dep]), columns=keep_input_num_dep)\n",
    "print('Shape test departure (num):',num_te_dep.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge categorical and numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape training input arrival: (215050, 434)\n",
      "Shape validation input arrival: (108720, 424)\n",
      "Shape test input arrival: (107366, 424)\n",
      "***\n",
      "Shape training input departure: (215023, 434)\n",
      "Shape validation input departure: (108689, 424)\n",
      "Shape test input arrival: (107323, 424)\n"
     ]
    }
   ],
   "source": [
    "# arrival set\n",
    "## Training\n",
    "df_tr_arr_raw = df_tr_arr_cat.drop(columns=keep_input_num_arr, axis=1).reset_index(drop=True)\n",
    "df_tr_arr_input = df_tr_arr_raw.merge(right=num_tr_arr, how='left', left_index=True, right_index=True)\n",
    "X_tr_arr = df_tr_arr_input.values\n",
    "print('Shape training input arrival:',X_tr_arr.shape)\n",
    "\n",
    "## Validation\n",
    "df_va_arr_raw = df_va_arr_cat.drop(columns=keep_input_num_arr, axis=1).reset_index(drop=True)\n",
    "df_va_arr_input = df_va_arr_raw.merge(right=num_va_arr, how='left', left_index=True, right_index=True)\n",
    "X_va_arr = df_va_arr_input.values\n",
    "print('Shape validation input arrival:',X_va_arr.shape)\n",
    "\n",
    "## Validation\n",
    "df_te_arr_raw = df_te_arr_cat.drop(columns=keep_input_num_arr, axis=1).reset_index(drop=True)\n",
    "df_te_arr_input = df_te_arr_raw.merge(right=num_te_arr, how='left', left_index=True, right_index=True)\n",
    "X_te_arr = df_te_arr_input.values\n",
    "print('Shape test input arrival:',X_te_arr.shape)\n",
    "print('***')\n",
    "\n",
    "# departure set\n",
    "## Training\n",
    "df_tr_dep_raw = df_tr_dep_cat.drop(columns=keep_input_num_dep, axis=1).reset_index(drop=True)\n",
    "df_tr_dep_input = df_tr_dep_raw.merge(right=num_tr_dep, how='left', left_index=True, right_index=True)\n",
    "X_tr_dep = df_tr_dep_input.values\n",
    "print('Shape training input departure:',X_tr_dep.shape)\n",
    "\n",
    "## Validation\n",
    "df_va_dep_raw = df_va_dep_cat.drop(columns=keep_input_num_dep, axis=1).reset_index(drop=True)\n",
    "df_va_dep_input = df_va_dep_raw.merge(right=num_va_dep, how='left', left_index=True, right_index=True)\n",
    "X_va_dep = df_va_dep_input.values\n",
    "print('Shape validation input departure:',X_va_dep.shape)\n",
    "\n",
    "## Validation\n",
    "df_te_dep_raw = df_te_dep_cat.drop(columns=keep_input_num_dep, axis=1).reset_index(drop=True)\n",
    "df_te_dep_input = df_te_dep_raw.merge(right=num_te_dep, how='left', left_index=True, right_index=True)\n",
    "X_te_dep = df_te_dep_input.values\n",
    "print('Shape test input arrival:',X_te_dep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line_name_AG\n",
      "line_name_EXT\n",
      "line_name_EXTL4\n",
      "product_id_AG\n",
      "product_id_EXT\n",
      "stop_id_8501055\n",
      "stop_id_8501060\n",
      "stop_id_8501061\n",
      "stop_id_8501401\n",
      "stop_id_8519077\n"
     ]
    }
   ],
   "source": [
    "# arrival set\n",
    "train_list = df_tr_arr_input.columns.tolist()\n",
    "valid_list = df_va_arr_input.columns.tolist()\n",
    "test_list = df_te_arr_input.columns.tolist()\n",
    "\n",
    "# identify columns which are in train set but not in valid or test sets\n",
    "for x in train_list:\n",
    "    if x in test_list: continue\n",
    "    else:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reindex shape validation input arrival: (108720, 434)\n",
      "Reindex shape test input arrival: (107366, 434)\n",
      "***\n",
      "Reindex shape validation input departure: (108689, 434)\n",
      "Reindex shape test input departure: (107323, 434)\n"
     ]
    }
   ],
   "source": [
    "# arrival set\n",
    "df_va_arr_input_reindex = df_va_arr_input.reindex(columns=df_tr_arr_input.columns,fill_value=0.0)\n",
    "X_va_arr_reindex = df_va_arr_input_reindex.values\n",
    "print('Reindex shape validation input arrival:',X_va_arr_reindex.shape)\n",
    "df_te_arr_input_reindex = df_te_arr_input.reindex(columns=df_tr_arr_input.columns,fill_value=0.0)\n",
    "X_te_arr_reindex = df_te_arr_input_reindex.values\n",
    "print('Reindex shape test input arrival:',X_te_arr_reindex.shape)\n",
    "print('***')\n",
    "\n",
    "# departure set\n",
    "df_va_dep_input_reindex = df_va_dep_input.reindex(columns=df_tr_dep_input.columns,fill_value=0.0)\n",
    "X_va_dep_reindex = df_va_dep_input_reindex.values\n",
    "print('Reindex shape validation input departure:',X_va_dep_reindex.shape)\n",
    "df_te_dep_input_reindex = df_te_dep_input.reindex(columns=df_tr_dep_input.columns,fill_value=0.0)\n",
    "X_te_dep_reindex = df_te_dep_input_reindex.values\n",
    "print('Reindex shape test input departure:',X_te_dep_reindex.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape training output delay arrival: (215050,)\n",
      "Shape training output important delay arrival: (215050,)\n",
      "Shape validation output delay arrival: (108720,)\n",
      "Shape validation output important delay arrival: (108720,)\n",
      "Shape test output delay arrival: (107366,)\n",
      "Shape test output important delay arrival: (107366,)\n",
      "***\n",
      "Shape training output delay departure: (215023,)\n",
      "Shape training output important delay departure: (215023,)\n",
      "Shape validation output delay departure: (108689,)\n",
      "Shape validation output important delay departure: (108689,)\n",
      "Shape test output delay departure: (107323,)\n",
      "Shape test output important delay departure: (107323,)\n"
     ]
    }
   ],
   "source": [
    "# arrival set\n",
    "## Training\n",
    "y_tr_arr_delay = df_tr_arr_cant['arrival_delay_bucket_final'].values\n",
    "y_tr_arr_imp_delay = df_tr_arr_cant['arrival_important_delay_bucket_final'].values\n",
    "print('Shape training output delay arrival:',y_tr_arr_delay.shape)\n",
    "print('Shape training output important delay arrival:',y_tr_arr_imp_delay.shape)\n",
    "\n",
    "## Validation\n",
    "y_va_arr_delay = df_va_arr_cant['arrival_delay_bucket_final'].values\n",
    "y_va_arr_imp_delay = df_va_arr_cant['arrival_important_delay_bucket_final'].values\n",
    "print('Shape validation output delay arrival:',y_va_arr_delay.shape)\n",
    "print('Shape validation output important delay arrival:',y_va_arr_imp_delay.shape)\n",
    "\n",
    "## Test\n",
    "y_te_arr_delay = df_te_arr_cant['arrival_delay_bucket_final'].values\n",
    "y_te_arr_imp_delay = df_te_arr_cant['arrival_important_delay_bucket_final'].values\n",
    "print('Shape test output delay arrival:',y_te_arr_delay.shape)\n",
    "print('Shape test output important delay arrival:',y_te_arr_imp_delay.shape)\n",
    "print('***')\n",
    "\n",
    "# departure set\n",
    "## Training\n",
    "y_tr_dep_delay = df_tr_dep_cant['departure_delay_bucket_final'].values\n",
    "y_tr_dep_imp_delay = df_tr_dep_cant['departure_important_delay_bucket_final'].values\n",
    "print('Shape training output delay departure:',y_tr_dep_delay.shape)\n",
    "print('Shape training output important delay departure:',y_tr_dep_imp_delay.shape)\n",
    "\n",
    "## Validation\n",
    "y_va_dep_delay = df_va_dep_cant['departure_delay_bucket_final'].values\n",
    "y_va_dep_imp_delay = df_va_dep_cant['departure_important_delay_bucket_final'].values\n",
    "print('Shape validation output delay departure:',y_va_dep_delay.shape)\n",
    "print('Shape validation output important delay departure:',y_va_dep_imp_delay.shape)\n",
    "\n",
    "## Test\n",
    "y_te_dep_delay = df_te_dep_cant['departure_delay_bucket_final'].values\n",
    "y_te_dep_imp_delay = df_te_dep_cant['departure_important_delay_bucket_final'].values\n",
    "print('Shape test output delay departure:',y_te_dep_delay.shape)\n",
    "print('Shape test output important delay departure:',y_te_dep_imp_delay.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7) Saving input and output features** <a name='save'/> | <a href=#index>Back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save them into a .npz file\n",
    "np.savez('capstone_inputoutput.npz',\n",
    "         # arrival set\n",
    "         df_tr_arr_input=df_tr_arr_input, # to get columns\n",
    "         df_tr_arr_input_columns=df_tr_arr_input.columns,\n",
    "         \n",
    "         X_tr_arr=X_tr_arr,\n",
    "         X_va_arr_reindex=X_va_arr_reindex,\n",
    "         X_te_arr_reindex=X_te_arr_reindex,\n",
    "         \n",
    "         y_tr_arr_delay=y_tr_arr_delay,\n",
    "         y_tr_arr_imp_delay=y_tr_arr_imp_delay,\n",
    "         \n",
    "         y_va_arr_delay=y_va_arr_delay,\n",
    "         y_va_arr_imp_delay=y_va_arr_imp_delay,\n",
    "         \n",
    "         y_te_arr_delay=y_te_arr_delay,\n",
    "         y_te_arr_imp_delay=y_te_arr_imp_delay,\n",
    "         # departure set\n",
    "         X_tr_dep=X_tr_dep,\n",
    "         X_va_dep_reindex=X_va_dep_reindex,\n",
    "         X_te_dep_reindex=X_te_dep_reindex,\n",
    "         \n",
    "         y_tr_dep_delay=y_tr_dep_delay,\n",
    "         y_tr_dep_imp_delay=y_tr_dep_imp_delay,\n",
    "         \n",
    "         y_va_dep_delay=y_va_dep_delay,\n",
    "         y_va_dep_imp_delay=y_va_dep_imp_delay,\n",
    "         \n",
    "         y_te_dep_delay=y_te_dep_delay,\n",
    "         y_te_dep_imp_delay=y_te_dep_imp_delay\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING input and output features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['df_tr_arr_input', 'df_tr_arr_input_columns', 'X_tr_arr', 'X_va_arr_reindex', 'X_te_arr_reindex', 'y_tr_arr_delay', 'y_tr_arr_imp_delay', 'y_va_arr_delay', 'y_va_arr_imp_delay', 'y_te_arr_delay', 'y_te_arr_imp_delay', 'X_tr_dep', 'X_va_dep_reindex', 'X_te_dep_reindex', 'y_tr_dep_delay', 'y_tr_dep_imp_delay', 'y_va_dep_delay', 'y_va_dep_imp_delay', 'y_te_dep_delay', 'y_te_dep_imp_delay']\n"
     ]
    }
   ],
   "source": [
    "# Load the npz file\n",
    "import numpy as np\n",
    "with np.load('capstone_inputoutput.npz', allow_pickle=False) as npz_file:\n",
    "    # It's a dictionary-like object\n",
    "    print(list(npz_file.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_merged_final: (215050, 434)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "with np.load('capstone_inputoutput.npz', allow_pickle=True) as npz_file:\n",
    "    # Load the arrays\n",
    "    # arrival set\n",
    "    df_tr_arr_input=npz_file['df_tr_arr_input']\n",
    "    df_tr_arr_input_columns=npz_file['df_tr_arr_input_columns']\n",
    "    \n",
    "    X_tr_arr = npz_file['X_tr_arr']\n",
    "    X_va_arr_reindex = npz_file['X_va_arr_reindex']\n",
    "    X_te_arr_reindex = npz_file['X_te_arr_reindex']\n",
    "    \n",
    "    y_tr_arr_delay = npz_file['y_tr_arr_delay']\n",
    "    y_tr_arr_imp_delay = npz_file['y_tr_arr_imp_delay']\n",
    "    y_va_arr_delay = npz_file['y_va_arr_delay']\n",
    "    y_va_arr_imp_delay = npz_file['y_va_arr_imp_delay']\n",
    "    y_te_arr_delay = npz_file['y_te_arr_delay']\n",
    "    y_te_arr_imp_delay = npz_file['y_te_arr_imp_delay']\n",
    "    # departure set\n",
    "    X_tr_dep = npz_file['X_tr_dep']\n",
    "    X_va_dep_reindex = npz_file['X_va_dep_reindex']\n",
    "    X_te_dep_reindex = npz_file['X_te_dep_reindex']\n",
    "    \n",
    "    y_tr_dep_delay = npz_file['y_tr_dep_delay']\n",
    "    y_tr_dep_imp_delay = npz_file['y_tr_dep_imp_delay']\n",
    "    y_va_dep_delay = npz_file['y_va_dep_delay']\n",
    "    y_va_dep_imp_delay = npz_file['y_va_dep_imp_delay']\n",
    "    y_te_dep_delay = npz_file['y_te_dep_delay']\n",
    "    y_te_dep_imp_delay = npz_file['y_te_dep_imp_delay']\n",
    "\n",
    "print('df_merged_final:', X_tr_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['operating_day_of_week_Friday', 'operating_day_of_week_Monday',\n",
       "       'operating_day_of_week_Saturday', 'operating_day_of_week_Sunday',\n",
       "       'operating_day_of_week_Thursday', 'operating_day_of_week_Tuesday',\n",
       "       'operating_day_of_week_Wednesday', 'operator_short_BC-cmBC',\n",
       "       'operator_short_BLS-bls', 'operator_short_LEB',\n",
       "       'operator_short_MBC', 'operator_short_MOB',\n",
       "       'operator_short_MVR-cev', 'operator_short_NStCM',\n",
       "       'operator_short_SBB', 'operator_short_TPC-al',\n",
       "       'operator_short_TPF', 'operator_short_TRAVYS-pbr',\n",
       "       'operator_short_TRAVYS-ysc', 'line_name_AG', 'line_name_EC',\n",
       "       'line_name_EXT', 'line_name_EXTL4', 'line_name_IC',\n",
       "       'line_name_IC1', 'line_name_IC5', 'line_name_IR', 'line_name_IR15',\n",
       "       'line_name_IR90', 'line_name_PE', 'line_name_R', 'line_name_RE',\n",
       "       'line_name_S', 'line_name_S1', 'line_name_S2', 'line_name_S3',\n",
       "       'line_name_S30', 'line_name_S4', 'line_name_S5', 'line_name_S50',\n",
       "       'line_name_S7', 'line_name_S8', 'line_name_S9', 'line_name_SL1',\n",
       "       'line_name_SL2', 'line_name_SL3', 'line_name_SL4', 'line_name_TER',\n",
       "       'line_name_TGV', 'product_id_AG', 'product_id_EC',\n",
       "       'product_id_EXT', 'product_id_IC', 'product_id_IR',\n",
       "       'product_id_PE', 'product_id_R', 'product_id_RE', 'product_id_S',\n",
       "       'product_id_TER', 'product_id_TGV', 'stop_id_8501014',\n",
       "       'stop_id_8501015', 'stop_id_8501023', 'stop_id_8501030',\n",
       "       'stop_id_8501031', 'stop_id_8501033', 'stop_id_8501035',\n",
       "       'stop_id_8501036', 'stop_id_8501037', 'stop_id_8501042',\n",
       "       'stop_id_8501045', 'stop_id_8501047', 'stop_id_8501048',\n",
       "       'stop_id_8501053', 'stop_id_8501054', 'stop_id_8501055',\n",
       "       'stop_id_8501056', 'stop_id_8501057', 'stop_id_8501058',\n",
       "       'stop_id_8501059', 'stop_id_8501060', 'stop_id_8501061',\n",
       "       'stop_id_8501062', 'stop_id_8501063', 'stop_id_8501064',\n",
       "       'stop_id_8501065', 'stop_id_8501066', 'stop_id_8501067',\n",
       "       'stop_id_8501068', 'stop_id_8501069', 'stop_id_8501080',\n",
       "       'stop_id_8501081', 'stop_id_8501082', 'stop_id_8501083',\n",
       "       'stop_id_8501084', 'stop_id_8501085', 'stop_id_8501087',\n",
       "       'stop_id_8501088', 'stop_id_8501089', 'stop_id_8501090',\n",
       "       'stop_id_8501091', 'stop_id_8501092', 'stop_id_8501093',\n",
       "       'stop_id_8501094', 'stop_id_8501095', 'stop_id_8501096',\n",
       "       'stop_id_8501097', 'stop_id_8501098', 'stop_id_8501099',\n",
       "       'stop_id_8501100', 'stop_id_8501103', 'stop_id_8501104',\n",
       "       'stop_id_8501105', 'stop_id_8501106', 'stop_id_8501107',\n",
       "       'stop_id_8501108', 'stop_id_8501110', 'stop_id_8501111',\n",
       "       'stop_id_8501112', 'stop_id_8501113', 'stop_id_8501114',\n",
       "       'stop_id_8501115', 'stop_id_8501116', 'stop_id_8501117',\n",
       "       'stop_id_8501118', 'stop_id_8501120', 'stop_id_8501121',\n",
       "       'stop_id_8501122', 'stop_id_8501123', 'stop_id_8501124',\n",
       "       'stop_id_8501125', 'stop_id_8501126', 'stop_id_8501127',\n",
       "       'stop_id_8501151', 'stop_id_8501152', 'stop_id_8501153',\n",
       "       'stop_id_8501154', 'stop_id_8501155', 'stop_id_8501156',\n",
       "       'stop_id_8501157', 'stop_id_8501159', 'stop_id_8501160',\n",
       "       'stop_id_8501161', 'stop_id_8501162', 'stop_id_8501163',\n",
       "       'stop_id_8501164', 'stop_id_8501165', 'stop_id_8501166',\n",
       "       'stop_id_8501167', 'stop_id_8501168', 'stop_id_8501169',\n",
       "       'stop_id_8501170', 'stop_id_8501171', 'stop_id_8501172',\n",
       "       'stop_id_8501173', 'stop_id_8501174', 'stop_id_8501175',\n",
       "       'stop_id_8501176', 'stop_id_8501177', 'stop_id_8501178',\n",
       "       'stop_id_8501179', 'stop_id_8501181', 'stop_id_8501191',\n",
       "       'stop_id_8501194', 'stop_id_8501198', 'stop_id_8501199',\n",
       "       'stop_id_8501200', 'stop_id_8501201', 'stop_id_8501202',\n",
       "       'stop_id_8501203', 'stop_id_8501260', 'stop_id_8501262',\n",
       "       'stop_id_8501263', 'stop_id_8501264', 'stop_id_8501265',\n",
       "       'stop_id_8501266', 'stop_id_8501280', 'stop_id_8501281',\n",
       "       'stop_id_8501282', 'stop_id_8501283', 'stop_id_8501284',\n",
       "       'stop_id_8501285', 'stop_id_8501286', 'stop_id_8501287',\n",
       "       'stop_id_8501288', 'stop_id_8501300', 'stop_id_8501301',\n",
       "       'stop_id_8501302', 'stop_id_8501303', 'stop_id_8501304',\n",
       "       'stop_id_8501306', 'stop_id_8501374', 'stop_id_8501375',\n",
       "       'stop_id_8501376', 'stop_id_8501377', 'stop_id_8501380',\n",
       "       'stop_id_8501381', 'stop_id_8501382', 'stop_id_8501383',\n",
       "       'stop_id_8501384', 'stop_id_8501385', 'stop_id_8501386',\n",
       "       'stop_id_8501388', 'stop_id_8501390', 'stop_id_8501391',\n",
       "       'stop_id_8501392', 'stop_id_8501393', 'stop_id_8501394',\n",
       "       'stop_id_8501395', 'stop_id_8501396', 'stop_id_8501397',\n",
       "       'stop_id_8501400', 'stop_id_8501401', 'stop_id_8501402',\n",
       "       'stop_id_8501446', 'stop_id_8501447', 'stop_id_8501452',\n",
       "       'stop_id_8501458', 'stop_id_8501459', 'stop_id_8501461',\n",
       "       'stop_id_8501468', 'stop_id_8501469', 'stop_id_8501470',\n",
       "       'stop_id_8501471', 'stop_id_8501472', 'stop_id_8501473',\n",
       "       'stop_id_8501474', 'stop_id_8501475', 'stop_id_8501476',\n",
       "       'stop_id_8501477', 'stop_id_8501479', 'stop_id_8501480',\n",
       "       'stop_id_8501481', 'stop_id_8501482', 'stop_id_8501483',\n",
       "       'stop_id_8501484', 'stop_id_8501485', 'stop_id_8501487',\n",
       "       'stop_id_8501488', 'stop_id_8501490', 'stop_id_8501491',\n",
       "       'stop_id_8501492', 'stop_id_8501493', 'stop_id_8501494',\n",
       "       'stop_id_8501495', 'stop_id_8501497', 'stop_id_8501498',\n",
       "       'stop_id_8501499', 'stop_id_8501554', 'stop_id_8501725',\n",
       "       'stop_id_8501727', 'stop_id_8504000', 'stop_id_8504003',\n",
       "       'stop_id_8504007', 'stop_id_8504010', 'stop_id_8504011',\n",
       "       'stop_id_8504012', 'stop_id_8504013', 'stop_id_8504014',\n",
       "       'stop_id_8504015', 'stop_id_8504016', 'stop_id_8504017',\n",
       "       'stop_id_8504020', 'stop_id_8504040', 'stop_id_8504120',\n",
       "       'stop_id_8504121', 'stop_id_8504122', 'stop_id_8504123',\n",
       "       'stop_id_8504126', 'stop_id_8504127', 'stop_id_8504130',\n",
       "       'stop_id_8504134', 'stop_id_8504135', 'stop_id_8504141',\n",
       "       'stop_id_8504144', 'stop_id_8504200', 'stop_id_8504201',\n",
       "       'stop_id_8504203', 'stop_id_8504291', 'stop_id_8504292',\n",
       "       'stop_id_8504293', 'stop_id_8504294', 'stop_id_8504295',\n",
       "       'stop_id_8504296', 'stop_id_8504297', 'stop_id_8504298',\n",
       "       'stop_id_8517484', 'stop_id_8517485', 'stop_id_8518452',\n",
       "       'stop_id_8519077', 'stop_id_8530064', 'stop_id_8530066',\n",
       "       'stop_id_8530067', 'stop_id_8530246', 'stop_id_8530261',\n",
       "       'stop_id_8530262', 'stop_id_8530263', 'stop_id_8530335',\n",
       "       'stop_id_8530355', 'stop_id_8530523', 'stop_id_8530783',\n",
       "       'stop_id_8587727', 'stop_id_8588193', 'stop_id_8593772',\n",
       "       'stop_id_8593773', 'stop_id_8593774', 'stop_id_8593775',\n",
       "       'stop_id_8593776', 'arrival_time_of_day_afternoon',\n",
       "       'arrival_time_of_day_early_morning', 'arrival_time_of_day_evening',\n",
       "       'arrival_time_of_day_midday', 'arrival_time_of_day_morning',\n",
       "       'arrival_time_of_day_peak_afternoon',\n",
       "       'arrival_time_of_day_peak_morning', 'start_middle_end_end_trip',\n",
       "       'start_middle_end_middle_stop', 'provider_short_LEB',\n",
       "       'provider_short_MBC', 'provider_short_MOB', 'provider_short_MVR',\n",
       "       'provider_short_NStCM', 'provider_short_SBB', 'provider_short_TL',\n",
       "       'provider_short_TPC', 'provider_short_TRAVYS', 'city_Aigle',\n",
       "       'city_Allaman', 'city_Apples', 'city_Arnex-sur-Orbe',\n",
       "       'city_Arzier-Le Muids', 'city_Assens', 'city_Avenches',\n",
       "       'city_Ballens', 'city_Baulmes', 'city_Bavois', 'city_Bercher',\n",
       "       'city_Bex', 'city_BiÃ¨re', 'city_Blonay', 'city_Bourg-en-Lavaux',\n",
       "       'city_BretonniÃ¨res', 'city_Bussigny', 'city_Bussy-Chardonney',\n",
       "       'city_Champvent', 'city_Chavornay', 'city_Cheseaux-sur-Lausanne',\n",
       "       'city_Chexbres', 'city_Chigny', \"city_ChÃ¢teau-d'Oex\",\n",
       "       'city_Concise', 'city_Coppet', 'city_Corcelles-prÃ¨s-Payerne',\n",
       "       'city_Corseaux', 'city_Denges', 'city_Echallens', 'city_EclÃ©pens',\n",
       "       'city_Ependes (VD)', 'city_EtagniÃ¨res', 'city_Etoy', 'city_Faoug',\n",
       "       'city_Fey', 'city_Genolier', 'city_Givrins', 'city_Gland',\n",
       "       'city_Grandson', 'city_Gryon', 'city_Henniez',\n",
       "       'city_Jouxtens-MÃ©zery', \"city_L'Abbaye\", \"city_L'Isle\",\n",
       "       'city_La Sarraz', 'city_La Tour-de-Peilz', 'city_Lausanne',\n",
       "       'city_Le Chenit', 'city_Le Lieu', 'city_Leysin', 'city_Lonay',\n",
       "       'city_Lucens', 'city_Lutry', 'city_Mies',\n",
       "       'city_Montagny-prÃ¨s-Yverdon', 'city_Montilliez', 'city_Montreux',\n",
       "       'city_Montricher', 'city_Morges', 'city_Moudon', 'city_Nyon',\n",
       "       'city_Ollon', 'city_Orbe', 'city_Ormont-Dessous',\n",
       "       'city_Ormont-Dessus', 'city_Oron', 'city_Pampigny', 'city_Payerne',\n",
       "       'city_Penthalaz', 'city_Prilly', 'city_Puidoux', 'city_Pully',\n",
       "       'city_Renens (VD)', 'city_Rivaz', 'city_Roche (VD)', 'city_Rolle',\n",
       "       'city_RomainmÃ´tier-Envy', 'city_Romanel-sur-Lausanne',\n",
       "       'city_RossiniÃ¨re', 'city_Rougemont', 'city_Saint-Cergue',\n",
       "       'city_Saint-LÃ©gier-La ChiÃ©saz', 'city_Saint-Prex',\n",
       "       'city_Saint-Saphorin (Lavaux)', 'city_Sainte-Croix', 'city_Tannay',\n",
       "       'city_TrÃ©lex', 'city_Valbroye', 'city_Valeyres-sous-Montagny',\n",
       "       'city_Vallorbe', 'city_Vevey', 'city_Veytaux',\n",
       "       'city_Villeneuve (VD)', 'city_Vufflens-la-Ville',\n",
       "       'city_Vufflens-le-ChÃ¢teau', 'city_Vuiteboeuf', 'city_Yens',\n",
       "       'city_Yverdon-les-Bains', 'city_Yvonand', 'canton_VD',\n",
       "       'transport_mode_stop_Unbekannt', 'transport_mode_stop_Zug',\n",
       "       'transport_mode_stop_Zug_Bus', 'transport_mode_stop_Zug_Metro',\n",
       "       'longitude_ch', 'latitude_ch', 'altitude'], dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr_arr_input_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
